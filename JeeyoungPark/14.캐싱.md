# 캐싱
캐싱: 자료를 임시 메모리에 저장하는 과정
캐싱의 목표 : hit(필요한 항목이 캐시에 존재하는 경우)를 최대화하고 miss(필요한 항목이 캐시에 존재하지 않는 경우)를 최소화하는 것

## 캐싱 설계
- 시간적 지역성(temporal locality): 최근에 접근한 메모리 위치를 다시 접근할 가능성이 높음
- 공간적 지역성(spatial locality): 최근에 접근한 메모리 위치 주변의 위치를 다시 접근할 가능성이 높음

-> 최적 캐싱 알고리즘: 새로운 항목을 삽입할 때 가장 나중에 사용될 항목이랑 교체하기


## LFU(최소 빈도 사용) 캐싱
- 운영체제는 어떤 블록이 메모리에서 참조된 횟수를 관리한다. 따라서 캐시 한계를 초과하는 경우 가장 참조 빈도가 낮은 항목을 삭제하는 것

구현 방법
- 캐시에 로딩되는 모든 블록에 카운터를 할당하여 참조 카운팅 -> 가장 낮은 카운팅 삭제

단점
- 짧은 시간에 집중적으로 참조된 항목이 높은 카운팅을 가져, 대부분의 시간 동안 더 자주 사용되는 다른 블록이 오히려 삭제되는 경우가 있다.
- 신규 항목은 카운팅이 낮다는 이유만으로 우선 삭제될 수 있다.

=> 잘 사용되지 않음

사용 예시
- 모바일 키보드 앱: 사용자가 동일한 단어를 자주 사용하기 때문에 빈도만으로 결정하기 좋음


## LRU(가장 오래전 사용) 캐싱
- 가장 오래된 항목을 먼저 제거하는 캐싱 알고리즘
- 캐시 리스트의 가장 앞쪽 항목이 가장 오래된 항목, 가장 뒤쪽이 가장 최근 항목 -> 신규 캐싱 항목은 가장 뒤에 추가됨

구현 방법
- 이중연결리스트
- capacity 매개변수로 허용되는 노드의 개수를 정의함

