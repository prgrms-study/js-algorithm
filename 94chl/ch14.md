캐싱
자료를 임시 메모리에 저장하는 과정
→ 해당 자료가 다시 필요할 때 쉽게 재취득 가능

목표

1. 히트 최대화(필요한 항목이 캐시에 존재하는 경우)
2. 미스 최소화(필요한 항목이 캐시에 존재하지 않는 경우)

캐시 설계 고려 요소

1. 시간적 지역성 temporal locality
   최근에 접근한 메모리 위치를 다시 접근할 가능성 高
2. 공간적 지역성 spatial locality
   최근에 접근한 메모리 위치의 주변 위치를 다시 접근할 가능성 高

LFU 캐싱
최소 빈도 사용 캐싱
운영체제가 메모리를 관리하기 위해 사용하는 캐싱 알고리즘
→ 한계를 초과 시, 참조 빈도가 낮은 항목을 삭제

한계

- 특정 시간에 한 블록에 빈도가 몰리는 경우, 평균적으로 많이 참조되는 블록이 상대적으로 빈도가 적어보여서 삭제될 위험 존재
- 신규 블록는 참조 빈도가 낮아서 삭제될 위험 존재

LRU 캐싱
참조한지 가장 오래된 항목을 먼저 제거하는 캐싱

- 참조한 항목은 리스트의 뒤로 이동(뒤가 가장 최신)
- 캐시에 없는 페이지에 접근하면 가장 앞에 있는 항목 제거(앞이 가장 올드)한 뒤 맨 뒤에 삽입
